---
title: "A2 - Análisis estadístico I"
author: "Fernando Antonio Barbeiro Campos - fbarbeiro@uoc.edu"

date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  html_document:
    toc: yes
  pdf_document:
    toc: yes
---
 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_libraries, include=FALSE}
library(knitr)
#\usepackage{mathtools}
```
# Introducción

<div style="text-align: justify">
En esta actividad usaremos el fichero de **World Happiness Report** “limpio”, es decir, después del preproceso que se ha realizado. Una vez el fichero está preparado, pasaremos a realizar análisis propios de la estadística descriptiva e inferencial. Os proporcionamos el fichero **2016_clean.csv** para que todos trabajéis con el mismo fichero de datos, independientemente del resultado obtenido en la actividad 1.
Recordamos que el fichero de datos recoge información sobre el grado de felicidad de países del mundo. El archivo contiene 157 registros y 13 variables. Estas variables son: *Country, Region, HR, HS, LCI, UCI, GpC, Family, LE, Freedom, GC, Generosity, DR donde HR: Happiness Rank, HS: Happiness Score, LCI y UCI*:
*Lower y Upper Confidence Interval, GpC: GDP per Capita, LE: Life Expectancy, GC: Trust Government Corruption, DR: Dystopia.*
Recordar que **no** se pueden realizar listados completos de los datos en la solución. El motivo es que se generan ficheros de salida con centenares de páginas que son muy difícil de trazar y corregir. Para comprobar las funcionalidades del código, podéis usar **head** y **tail** que solo muestran unas líneas del fichero.
</div>

```{r chunck1}
# Loading the dataframe
df <- read.csv("2016_clean.csv")
head(df)
```

# 1. Estadística Descriptiva
<div style="text-align: justify">
*A continuación, se estudiarán algunos valores centrales y de dispersión de algunas variables del fichero. Realizar los pasos que se indican a continuación.*
</div>

## 1.1 Valores centrales de HS (*Happiness Score*)
<p style="text-align: justify">
Calcular la media, mediana y el sumario de cinco números (de Tukey) del valor HS Happiness Score de toda la muestra. A continuación, visualizar la distribución de este valor en un diagrama de caja (boxplot) e interpretar el resultado. Finalmente, visualizar otro diagrama de caja donde se muestre el valor de HS para cada región. Es decir, en el mismo gráfico debe haber una caja para cada región representada en el fichero. Interpretar los gráficos.
</p>
### Respuesta
```{r chunck2}
N <- length(df$HS)
# Media de Happiness Score
mean(df$HS) # Using function
sum(df$HS)/N # Manually calculating

#Mediana
median(df$HS)
HS_sorted <- sort(df$HS)

if((N %% 2) == 0) {
  print(paste("Mi mediana calculada es", (HS_sorted[floor((N+1)/2)] + HS_sorted[ceiling((N+1)/2)]) / 2))
} else {
  print(paste("Mi mediana calculada es", HS_sorted[(N+1)/2]))
}

# five numbers (Tukey)
fivenum(df$HS)
# five numbers + media
summary(fivenum(df$HS))

# One by one - manually
min(df$HS)
quantile(df$HS, 0.25) # Mediana del "bottom half"
median(df$HS)
quantile(df$HS, 0.75) # Mediana del "top half"
max(df$HS)

boxplot(df$HS)
```

<p style="text-align: justify">
La interpretación del gráfico de caja sobre la distribución de los valores de *Happiness Score* es bastante sencilla. En la parte más inferior del gráfico tenemos la línea del **valor mínimo** (2.905, según hemos extraído en  el sumario de cinco números). Entonces el dibujo de la caja en sí empieza en el **primer cuartil Q1** - 4.404 - que representa 25%, o sea, la mediana del *bottom half* de nuestra muestra. La próxima línea que tenemos trazada más en negrita es **la mediana - 5.314**, y en la parte superior de la caja, el **cuartil Q3 75%** - 6.269 -> mediana del *top half* de la muestra. Finalmente, la última línea superior arriba de la caja llega hasta al **valor máximo** de la muestra que es 7.526.
</p>

```{r chunck3}
summary(df$Region)

# Grafico para cada región representada
boxplot(df$HS ~ df$Region, main="Happiness Score by Region", ylab="Happiness Score", las=2)
```

##1.2 Cálculos sobre Generosity e identificación de outliers
<p style="text-align: justify">
Calcular la media, mediana y el sumario de cinco números (de Tukey) del valor Generosity de toda la muestra. Visualizar en un diagrama de caja (boxplot) e interpretar el resultado. ¿Existe algún outlier observable en HS o en Generosity? ¿Cómo afectan los outliers a los valores centrales calculados?
</p>

### Respuesta
```{r chunck4}
mean(df$Generosity) 
median(df$Generosity)
fivenum(df$Generosity)
summary(fivenum(df$Generosity))
boxplot(df$Generosity, main="Box plot Generosity")
```
<p style="text-align: justify">
Nuestro boxplot permite observar algunos valores outliers en *Generosity*: empezamos por la parte de abajo del gráfico: considerando que es un conjunto de datos que ha pasado por el preproceso (o sea, está limpio), las entradas de **valores mínimos** están en 0.0. El primer cuartil **Q1** empieza en 0.1546, con la línea **mediana** en negrita a 0.2225. Mientras tanto, el **Q3** representa un valor de 0.3119. Y por arriba de la línea max, **hay una serie de *outliers*** alrededor del valor 0.6 y llegando hasta el **máximo** de 0.8197.
</p>
<p style="text-align: justify">
Los *outliers* afectan especialmente a la media (**poco robusta**). Y cuando la muestra es pequeña, el efecto se nota aún más acentuado. Para representar que puede pasar, veamos un ejemplo:
</p>


```{r chunck5}
#¿Cómo afectan los outliers a los valores centrales calculados?
i1 <- c(1,1,1,2,1,1,2,1,1,2,1,3,3,2,3,2,2,4,1,1)
mean(i1)
median(i1)

i2 <- c(i1, 150)
mean(i2)
median(i2)
```

<p style="text-align: justify">
En **i1** se observa un conjunto bastante uniformemente distribuído, sin *outliers*, por lo tanto, la media y mediana están cerca una de la otra. Sin embargo, cuando añadimos un *outlier* en un nuevo conjunto **i2**, los valores han cambiado muchísimo para la media - ha subido hacia al valor más alto. Mientras tanto, mediana mantuvo un valor en el medio del listado. Este es un ejemplo de que acabamos de decir sobre la afectación de **medidas poco robustas**.
</p>

##1.3 Cálculos de dispersión
<p style="text-align: justify">
Calcular la dispersión del valor de Happiness Score usando las siguientes medidas: rango intercuartílico, varianza y desviación típica.
</p>

### Respuesta

```{r chunck6}
happiness <- df$HS
median(happiness)

ri <- quantile(happiness,.75) - quantile(happiness,.25)
print(paste("Rango Intercuartílico", ri))

#rango intercuartílico
IQR(happiness)

#varianza (suma del cuadrado de las desviaciones c respecto media / N)
var(happiness)

# Desviacion tipica - raiz varianza
sd(happiness) 
```


##1.4 Cálculos de dispersión manuales
<p style="text-align: justify">
Escribir una función denominada **my.mean** en R que calcule la media de un vector numérico. Escribir otra función denominada **my.var** que calcule la varianza de un vector numérico.
A continuación, llamar a la función **my.var** para obtener el valor de varianza de *HS* y de *Generosity*. Comprobar que el resultado sea el mismo que con la función correspondiente de R.
</p>
<p style="text-align: justify">
**Nota:** el objetivo de esta pregunta es, por una parte, aprender a crear funciones en R. Las funciones son útiles cuando un determinado cálculo se debe realizar varias veces. En este caso, las funciones que calculan medias y varianzas ya están definidas en R, pero realizamos de nuevo estas funciones como ejemplo ilustrativo. El segundo objetivo de esta pregunta es comprender cómo se realiza el cálculo de la media y la varianza.
</p>
### Respuesta
```{r chunck7}
my.mean <- function(x) {
  # media
  sum(x)/length(x)
}

my.var <- function(x) {
  # varianza muestral
  media_x <- my.mean(x)
  sum((x - media_x)^2) / (length(x) - 1)
}

my.validator <- function(x, y, operation, field) {
  if(x == y){
    print(paste("Well done, the ",operation," for ",field," is ", round(x,6)))
  } else {
    print(paste("Error - the function defined for ",operation, " returned values: ",x," != ",y))
  }
}

my.validator(my.mean(df$HS), mean(df$HS), "MEAN", "HS")
my.validator(my.var(df$HS), var(df$HS), "VAR", "HS")
my.validator(my.var(df$Generosity), var(df$Generosity), "VAR", "Generosity")
```
<hr />
# 2. Estadística Inferencial
<div style="text-align: justify">

## 2.1 Media de HS de todos los países
<p style="text-align: justify">
HS toma valores en una escala de 0 a 10, donde 10 es la máxima felicidad y 0 la mínima. ¿Podemos afirmar con un nivel de confianza del 99% que el valor medio de HS de todos los países del mundo es 5.0?
</p>
<p style="text-align: justify">
Para poder responder a esta pregunta, aplicaremos los métodos de contrastes de hipótesis. Para ello, seguir los pasos que se indican a continuación.
</p>
<p style="text-align: justify">
**Nota:** Para resolver esta pregunta y todas las siguientes del apartado de Estadística Inferencial, debéis hacer los cálculos manualmente, sin usar funciones de R que calculen el contraste directamente (del tipo t.test que se proporcionan desde R u otras similares que se puedan proporcionar en diferentes librerías). Podéis usar estas funciones de R sólo para comprobar vuestro resultado del cálculo manual.
</p>
<p style="text-align: justify">
Como sugerencia, si lo deseáis, podéis crear una función propia que realice los cálculos y esta función la podréis usar a lo largo de la actividad (en el caso de que sea reutilizable).
</p>

#### Respuesta
### 2.1.1 Escribir la hipótesis nula y alternativa
##### Hipótesis nula *H*<sub>0</sub>
<p style="text-align: justify">
Indica la hipótesis de partida, en este caso, la hipótesis de que los *HS* de todos los países del mundo es 5.0.
</p>

**H<sub>0</sub> : &mu; = 5.0 (HS)**

<br />

##### Hipótesis alternativa *H*<sub>1</sub>
<p style="text-align: justify">
Indica que se ha producido cambio con respecto a la situación propuesta inicialmente.
</p>

**H<sub>1</sub> : &mu; $\neq$ 5.0 (HS)**

### 2.1.1 Escribir qué tipo de contraste aplicaréis
<p style="text-align: justify">
El tipo de contraste utilizado será el contraste de hipótesis, o sea, comparar predicciones con la realidad que observamos y además, como tenemos *N* > 30, tendremos una funcción pivotal *Z* que será explicada más adelante en el codigo. Si dentro del margen de error que nos permitimos admitir (nivel de significación), hay coincidencia, aceptaremos la hipótesis y en caso contrario la rechazaremos.
</p>
<p style="text-align: justify">
Dentro del tema de contraste de hipótesis, tenemos que el nivel de significación &alpha; de un contraste es el error máximo de tipo I (rechazar *H<sub>0</sub>* cuando ésta es cierta) que estamos dispuestos a asumir, o sea, 1%, según el enunciado. Luego: &alpha; = 0,01. En mi punto de vista, tenemos un contraste conservador que tiende a aceptar la *hipótesis nula*.
</p>

### 2.1.3 Realizar los cálculos del contraste de hipótesis: calcular el estadístico de contraste observado y el valor crítico
<p style="text-align: justify">
Realizaremos primero el calculo del *estadístico de contraste* recordando que tal valor se usa para decidir si rechazamos la hipótesis nula o no.
</p>

```{r chunck8}
my.contrast <- function(x, mean_hipothesis){
  z <- (mean(x) - mean_hipothesis) / (sd(x) / sqrt(length(x)))
  print(paste("Contraste estadístico: ", z))
  z
}
mean_informed_h0 <- 5.0
z = my.contrast(df$HS, mean_informed_h0)

```
<p style="text-align: justify">
Para nuestro ejemplo, como hemos definido un contraste bilateral *(-z, z)*, tendrémos la conocida probabilidad de dos colas, donde, para definir **valor crítico**, tendrémos &alpha; = 0,01, luego:  *z<sub>&alpha;/2</sub>* = 2.576 y -2.576 (datos sacados de la tabla distribución normal).
</p>


### 2.1.4 Interpretar el resultado
<p style="text-align: justify">
Si nos fijamos que tenemos dos colas y estamos siguiendo las tablas de distribución normal respecto el *valor crítico* que hemos definido en el paso anterior, ahora es necesario ubicar el valor obtenido en el cálculo del estadístico de contraste (función Pivotal).
</p>
<p style="text-align: justify">
Para ello se puede usar una **curva de distribución**, donde tendrémos 2 zonas distintas: *Región de Rechazo o de Aceptación* (respectivamente vamos a llamar de RR y RA). RR sirvirá para los valores inferiores y superiores al valor crítico, esto es, z < -2.576 o z > 2.576. La región por el medio será la RA.
</p>
<p style="text-align: justify">
Como nuestro cálculo resulta en 4.19451 significa que estamos ubicados por arriba del Rechazo, con esto, deberíamos rechazamos la hipótesis nula *H<sub>0</sub>*.
</p>


### 2.1.5 Calcular el valor p y explicar cómo se interpreta su resultado
<p style="text-align: justify">
Primeramente el calculo manual (y luego usando la libreria del p.test para validar):
</p>
```{r chunck9}
mean_informed <- 5.0
z = my.contrast(df$HS, mean_informed)

2 * pt(-abs(z), df = length(df$HS) - 1)

# Confirmando p value
t.test(df$HS, mu=5.0, conf.level = 0.99)
```
<p style="text-align: justify">
Como tenemos un contraste bilateral y hemos definido (conforme indica el codigo arriba) un valor de contraste de 4.1945, este valor sirve para definir el rango de aceptación, esto es, aceptamos la hipótesis nula si el p valor está entre -4.1945 y 4.1945. En la secuencia se hizo manualmente el calculo del p-value y obtuvimos el valor de 4.5721. Por lo tanto, en cima del rango de aceptación, o sea, tenemos que rechazarlo.
</p>

<p style="text-align: justify">
Para asegurar que los calculos estaban bien hechos, he utilizado la función de la libreria t.test y los resultados han coincidido.
</p>


## 2.2 Media de HS de los países europeos

<p style="text-align: justify">
¿Podemos afirmar con un nivel de confianza del 99% que el valor medio de HS de los países europeos es superior a 5.7? ¿Y al 95%?
</p>
<p style="text-align: justify">
**Nota:** Considerar los países de la muestra que pertenezcan a las regiones *“Central and Eastern Europe”* y *“Western Europe”*.
</p>
<p style="text-align: justify">
Al igual que en la pregunta anterior, no podéis usar funciones de R que ya proporcionen el contraste hecho. Debéis hacer los cálculos manualmente (o bien usar funciones propias que hayáis implementado vosotros mismos.)
</p>

#### Respuesta
### 2.2.1 Escribir la hipótesis nula y la hipótesis alternativa
##### Hipótesis nula *H*<sub>0</sub>
<p style="text-align: justify">
Indica la hipótesis de partida, en este caso, la hipótesis de que los *HS* de todos los países europeos es de 5.7.
</p>

**H<sub>0</sub> : &mu; > 5.7 (HS-Europe)**

<br />

##### Hipótesis alternativa *H*<sub>1</sub>
<p style="text-align: justify">
Indica que se ha producido cambio con respecto a la situación propuesta inicialmente.
</p>

**H<sub>1</sub> : &mu; $\leq$ 5.7 (HS-Europe)**

### 2.2.2 Detallar qué tipo de test aplicaréis
<p style="text-align: justify">
El tipo de test, otra vez, será el contraste de hipótesis,  donde tendremos una funcción pivotal *Z* que será explicada más adelante en el codigo. Si dentro del margen de error que nos permitimos admitir (nivel de significación: inicialmente 1% y después 5%, conforme enunciado), hay coincidencia, aceptaremos la hipótesis y en caso contrario la rechazaremos.
</p>
<p style="text-align: justify">
Dicho nuestro datos tienen: &alpha; = 0,01. / &alpha; = 0.05 en un según momento.
</p>
<p style="text-align: justify">
He elegido el contraste de hipótesis porque mirando hacia el contraste de varianza, indicaba para la ocurrencia de más de 2 grupos - y lo mismo para análisis de muestreo.
</p>


### 2.2.3 Realizar los cálculos del estadístico de contraste observado y el valor crítico.
<p style="text-align: justify">
He realizado un filtro para poder tener un subset con los datos que son especificamente de países de las regiones indicadas y he aplicado las mismas funciones anteriormente creadas. Veamos:
</p>
```{r chunck10}
hs_europe <- subset(df, df$Region=="Central and Eastern Europe" | df$Region=="Western Europe")
head(hs_europe)
mean_europe_h0 <- 5.7
z = my.contrast(hs_europe$HS, mean_europe_h0)
```

<p style="text-align: justify">
Dado que hay 2 **niveles de significación**, especificamente 1% y 5% que queremos mirar, quedaremos con:
</p>

*Valor crítico para 1%*: **2.33**
<br />
*Valor crítico para 5%*: **1.65**

<p style="text-align: justify">
La manera para encontrar ha sido utilizando la tabla de distribución normal estandar. En el eje de filas, encontramos 2.3 y 1.6 y en el eje de columnas _._3 y _._5.
</p>

### 2.2.4 Interpretar el resultado

<p style="text-align: justify">
En primer lugar, debemos decir que este es un resultado muy interesante, con un nivel de confianza 99% tendríamos como rechazado la hipótesis nula H<sub>0</sub>, esto porque el valor crítico de 2.3 es > que el valor del estadístico de contraste 1.6777. Mientras tanto, con un nível de confianza 95% se podría confirmar / aceptar la hipótesis nula, o sea, *&mu; > 5.7* porque 1.6777 > 1.65 definido. 
</p>

### 2.2.5 Calcular el valor p e interpretar el resultado

```{r chunck11}
my.p_value <- function(z, vector_param){
  p = 2 * pt(-abs(z), df = length(hs_europe$HS) - 1)
  p
}

my.p_value(z, hs_europe$HS)
t.test(hs_europe$HS, mu=mean_europe_h0, conf.level = 0.99)
t.test(hs_europe$HS, mu=mean_europe_h0, conf.level = 0.95)
```



## 2.3 Intervalo de confianza de HS

<p style="text-align: justify">
Calcular el intervalo de confianza al 99% del valor de HS. Interpretar el resultado y comparar los resultados con los obtenidos anteriormente.
</p>
<p style="text-align: justify">
**Nota:** Recordad que no podéis usar funciones de R que ya proporcionen el cálculo del intervalo de confianza hecho. Debéis hacer los cálculos manualmente (o bien usar funciones propias que hayáis implementado vosotros mismos.)
</p>


#### Respuesta
<p style="text-align: justify">
Para calcular el intervalo de confianza he utilizado una formula que se parece con:

##### average +- z-score * standardError

Las dos ultimas salidas representan el lower
</p>

```{r chunck12}
n <- length(df$HS)
m <- mean(df$HS)

conf.level <- 0.99
z <- qt((1+conf.level)/2, df=n-1)
se <- sd(df$HS)/sqrt(n)
ci <- z * se

range_min <- m - ci
range_max <- m + ci
```
<p style="text-align: justify">
Significa que tenemos 99% de confianza que nuestra población va a estar en entre el rango de **5.144582** y **5.619788**. 
</p>
<p style="text-align: justify">
Si nos fijamos en el ejercicio 2.1.5, podemos confirmar que ya habíamos llegado a este valor mientras ejecutabamos la función t.test para confirmar que nuestro resultado anterior estaba adecuado, o sea, el calculo atual también se confirma por el ítem comentado.
</p>

## 2.4 Contrastes entre regiones
<p style="text-align: justify">
Nos preguntamos si el nivel de felicidad de los países que pertenecen a las regiones europeas (*“Western Europe”* y *“Central and Eastern Europe”*) tienen un nivel de felicidad (HS) superior al resto de países de la muestra, con un nivel de confianza del 97%. Seguir los pasos siguientes.
</p>
<p style="text-align: justify">
**Nota:** Recordad que no podéis usar funciones R que calculen el contraste. Debéis realizar los cálculos o bien usar funciones propias que hayáis implementado vosotros mismos.
</p>

#### Respuesta
### 2.4.1 Preparar los datos
<p style="text-align: justify">
Crear dos data frames que contengan por separado los países que pertenecen a las regiones europeas mencionadas y por otra parte, el resto de países.
</p>

```{r chunck13}
hs_europe <- subset(df, df$Region=="Central and Eastern Europe" | df$Region=="Western Europe")
head(hs_europe)
hs_no_europe <- subset(df, df$Region!="Central and Eastern Europe" & df$Region!="Western Europe")
head(hs_no_europe)
```

### 2.4.2 Escribir la hipótesis nula y alternativa
##### Hipótesis nula *H*<sub>0</sub>
**H<sub>0</sub> : &mu;<sub>1</sub> > &mu;<sub>2</sub> (HS Europe > Rest of the world)**

<br />

##### Hipótesis alternativa *H*<sub>1</sub>
**H<sub>1</sub> : &mu;<sub>1</sub> < &mu;<sub>2</sub> (HS Europe < Rest of the world)**

###2.4.3 Detallar qué tipo de contraste usaréis
<p style="text-align: justify">
Para el escenario detallado usaremos el contraste de dos muestras, más especificamente **contraste sobre la diferencia de medias**. La opción por tal contraste es teniendo en cuenta que las muestras son de la misma variable (es decir, *Happiness Score*) y se busca identificar más informaciones de 2 poblaciones distintas.
</p>

###2.4.4 Realizar los cálculos de valor observado, valor crítico y valor p
Recordando que &alpha; = 0.03, veamos el calculo para la definición de los valores pedidos
```{r chunck14}
x1 <- hs_europe$HS
x2 <- hs_no_europe$HS
n1 <- length(x1)
n2 <- length(x2)

t <- (mean(x1) - mean(x2)) / sqrt(var(x1) / n1 + var(x2) / n2)
t

distf.num <- (var(x1) / n1 + var(x2) / n2)^2
distf.denom <- var(x1)^2 / (n1^2 * (n1 - 1)) + var(x2)^2 / (n2^2 * (n2 - 1))
distf <- distf.num / distf.denom
distf

# Para confirmar que los calculos estan bien hechos miramos t.test
t.test(hs_europe$HS, hs_no_europe$HS)
```


## 2.5 Contrastes entre años
<p style="text-align: justify">
Nos preguntamos si el nivel de felicidad ha aumentado del año 2016 al año 2017. Para ello os suministramos el fichero 2017.csv que tenéis adjunto. Debéis comparar los niveles de felicidad del año 2016 con los del 2017 y responder si podemos afirmar con un nivel de confianza del 90% si la felicidad ha aumentado del año 2016 al 2017. Seguir los pasos que se indican a continuación.
</p>
<p style="text-align: justify">
**Nota:** Recordad que no podéis usar funciones R que calculen el contraste. Debéis realizar los cálculos o bien usar funciones propias que hayáis implementado vosotros mismos.
</p>

#### Respuesta
###2.5.1 Especificar qué tipo de contraste aplicaréis y justificar
<p style="text-align: justify">
Contraste de hipótesis sobre la diferencia de medidas poblacionais - coge 2 muestras para contrastar hipótesis sobre su diferencia (construyendo intervalos de confianza para esta diferencia). No es lo mismo que datos aparejados.
</p>
###2.5.2 Preparar los datos para aplicar el cálculo
```{r chunck15}
df2017 <- read.csv("2017.csv")
summary(df2017)
df2016 <- read.csv("2016_clean.csv")
summary(df2016)

colnames(df2017)[which(names(df2017) == "Happiness.Score")] <- "HS"

```
###2.5.3 Escribir la hipótesis nula y alternativa
##### Hipótesis nula *H*<sub>0</sub>
**H<sub>0</sub> : &mu;<sub>1</sub> < &mu;<sub>2</sub> (HS 2016 < HS 2017)**

<br />

##### Hipótesis alternativa *H*<sub>1</sub>
**H<sub>1</sub> : &mu;<sub>1</sub> $\geq$ &mu;<sub>2</sub> (HS 2016 >= HS 2017)**

###2.5.4 Realizar los cálculos apropiados
<p style="text-align: justify">
Contraste de hipótesis sobre la diferencia de medidas poblacionais - coge 2 muestras para contrastar hipótesis sobre su diferencia (construyendo intervalos de confianza para esta diferencia). No es lo mismo que datos aparejados.
</p>

```{r chunck16}
x1 <- df2016$HS
x2 <- df2017$HS
n1 <- length(x1)
n2 <- length(x2)

t <- (mean(x1) - mean(x2)) / sqrt(var(x1) / n1 + var(x2) / n2)
t

distf.num <- (var(x1) / n1 + var(x2) / n2)^2
distf.denom <- var(x1)^2 / (n1^2 * (n1 - 1)) + var(x2)^2 / (n2^2 * (n2 - 1))
distf <- distf.num / distf.denom
distf
# Para confirmar que los calculos estan bien hechos miramos t.test
t.test(x1, x2)
```


